# 👋 Hi, I'm Albert Glenn

💾 **Data Engineering** | ⚙️ Pipeline Performance & Cost Optimization | ☁️ Cloud + Streaming | 📈 Data for Business Impact

---

## 🚀 About Me

I build scalable, secure, and **cost-efficient** data systems that transform raw data into trusted, high-quality assets for analytics, machine learning, and product decision-making.

**My edge:**
I design pipelines that **reduce compute/storage costs** while improving **speed, quality, and data availability** — enabling faster insights with lower cloud bills.

I’m completing the **Zero to Mastery Data Engineering Career Path** and applying each skill through portfolio projects focused on healthcare and finance.

---

## 💡 Business Impact Engineering

I prioritize **performance + cost optimization + governance**:

* 📉 Lower compute/storage spend using **Delta Lake**
  *(partitioning, Z-ordering, file compaction, caching)*
* ⚡ Faster ETL + analytics → **less runtime, fewer cluster-hours**
* 🔁 ELT + **Bronze/Silver/Gold** layers for reuse + reliability
* 🔐 Schema enforcement + RBAC for strong security compliance
* 🚀 Faster delivery of BI & ML → **better business outcomes**

> My goal: help companies **do more with data while spending less**.

---

## 🧱 What I Build

✅ Batch + streaming pipelines (Kafka, Spark, S3)
✅ Data lakes with **Delta Lake** / Lakehouse Architecture
✅ OLTP + OLAP modeling (Star Schemas)
✅ Secure environments (IAM, RBAC, .env credential mgmt)
✅ Analytics + ML-ready data products
✅ Workflow automation + CI/CD practices

I combine **data engineering excellence** with **business value delivery**.

---

## 🛠️ Tech Stack

**Languages / Data:** Python, SQL (PostgreSQL)
**Data Engineering:** Spark, Kafka, Airflow, Databricks, S3, Glue, Athena
**Data Modeling:** Parquet/Delta Lake, ACID guarantees, Z-order, partitioning
**Analytics + ML (supporting skills):** Power BI, Scikit-learn, TensorFlow, Streamlit
**DevOps:** Docker, Git/GitHub, CI/CD (in progress)
**Cloud:** AWS (Primary), Azure experience, Databricks

---

## 🎯 Current Focus

* Databricks **Delta Lake** performance + cost optimization
* Distributed compute + **Spark SQL** tuning
* Real-world **AWS Data Lake** architecture
* System design + SQL optimization interview prep
* Publishing portfolio case studies to GitHub & Medium

---

## 📌 Featured Project: Healthcare Data Engineering Pipeline

An end-to-end pipeline enabling **heart disease insights**:

* ✅ Raw → Bronze → Silver → Gold data architecture
* ✅ Spark transformations & quality checks
* ✅ S3 + Glue/Athena for governance + SQL analytics
* ✅ Delta Lake optimizations to cut cost and boost performance
* ✅ Power BI dashboards for clinical analytics

ML component in progress:
👉 [https://github.com/albe290/Heart-Disease-Prediction](https://github.com/albe290/Heart-Disease-Prediction)

> **Planned Impact:** ~30–40% reduction in ETL runtime with Delta optimizations

---

## 🔄 Coming Next: Real-Time Fraud Detection Pipeline

* Kafka streaming ingestion
* Spark Structured Streaming transformation
* Z-ordered Delta tables for high-speed querying
* Real-time risk scoring + dashboard alerts

> Showcasing **low-latency analytics** with controlled cloud spend.

---

## 📫 Connect with Me

* 💼 LinkedIn: [https://www.linkedin.com/in/aalbertglenn/](https://www.linkedin.com/in/aalbertglenn/)
* ✍🏽 Medium: [https://medium.com/@AlbertGlenn](https://medium.com/@AlbertGlenn)
* 🌐 Portfolio: *Coming Soon*

---

If you’re building modern data platforms focused on **performance + cost efficiency**, I’d love to collaborate.

--


If you're building data platforms with performance and fiscal responsibility, let’s talk.
I’m open to collaboration and full-time Data Engineering roles — especially in healthcare, sports analytics, and financial intelligence.





